{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e2f976f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Huseyin\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Huseyin\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBartForSequenceClassification: ['model.decoder.version', 'model.encoder.version']\n",
      "- This IS expected if you are initializing TFBartForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBartForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBartForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri Seti:\n",
      "                                             comment\n",
      "0  mum eriyince biter dedim 5 mum 3 gaz lambası 3...\n",
      "1  Youtubeda o kadar detaylı anlatan hoca varken ...\n",
      "2  Tersten de izledim integrali de hallettim hoca...\n",
      "3   anne şu video bitsin öyle gideceğim ekmek almaya\n",
      "4   Kesinlikle imdb top 5'e girer. Mükemmel bir film\n",
      "\n",
      "Eksik değerler:\n",
      "comment    0\n",
      "dtype: int64\n",
      "\n",
      "Etiketlenmiş Veri:\n",
      "                                             comment sentiment     score\n",
      "0  mum eriyince biter dedim 5 mum 3 gaz lambası 3...  Negative  0.653513\n",
      "1  Youtubeda o kadar detaylı anlatan hoca varken ...  Negative  0.600888\n",
      "2  Tersten de izledim integrali de hallettim hoca...  Negative  0.547657\n",
      "3   anne şu video bitsin öyle gideceğim ekmek almaya  Positive  0.456882\n",
      "4   Kesinlikle imdb top 5'e girer. Mükemmel bir film  Positive  0.635313\n",
      "Etiketlenmiş veri seti 'etkitelenen_veri.csv' olarak kaydedildi.\n",
      "\n",
      "Etiket Frekansları:\n",
      "sentiment\n",
      "Negative    577\n",
      "Positive    348\n",
      "Neutral     346\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#etiket verme\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "candidate_labels = [\"Positive\", \"Negative\", \"Neutral\"]\n",
    "\n",
    "csv_file_path = 'youtube.csv'\n",
    "\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "\n",
    "print(\"Veri Seti:\")\n",
    "print(df.head())  \n",
    "\n",
    "print(\"\\nEksik değerler:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "df = df.dropna(subset=['comment'])\n",
    "\n",
    "def classify_comment(comment):\n",
    "    if isinstance(comment, str):\n",
    "        result = classifier(\n",
    "            comment, \n",
    "            candidate_labels, \n",
    "            hypothesis_template=\"The sentiment of this text is {}.\"\n",
    "        )\n",
    " \n",
    "        max_score = max(result[\"scores\"])\n",
    "        label = result[\"labels\"][0]\n",
    "\n",
    "        if max_score < 0.45: \n",
    "            label = \"Neutral\"\n",
    "        return label, max_score\n",
    "    return None, None\n",
    "\n",
    "\n",
    "df[['sentiment', 'score']] = df['comment'].apply(lambda x: classify_comment(x)).apply(pd.Series)\n",
    "\n",
    "\n",
    "print(\"\\nEtiketlenmiş Veri:\")\n",
    "print(df.head())  \n",
    "\n",
    "\n",
    "output_file_path = 'etkitelenen_veri.csv'\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Etiketlenmiş veri seti '{output_file_path}' olarak kaydedildi.\")\n",
    "\n",
    "\n",
    "print(\"\\nEtiket Frekansları:\")\n",
    "print(df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bc55de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
